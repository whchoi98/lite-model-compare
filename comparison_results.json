{
  "meta": {
    "title": "AWS Bedrock 경량 모델 비교 테스트",
    "date": "2026-02-13",
    "region": "us-east-1",
    "max_tokens": 4096,
    "total_tests": 5
  },
  "models": {
    "haiku-4.5": {
      "name": "Claude Haiku 4.5",
      "model_id": "us.anthropic.claude-haiku-4-5-20251001-v1:0",
      "pricing_per_1M_tokens": {
        "input": 1.0,
        "output": 5.0
      }
    },
    "qwen-3.2": {
      "name": "Qwen 3 32B",
      "model_id": "qwen.qwen3-32b-v1:0",
      "pricing_per_1M_tokens": {
        "input": 0.5,
        "output": 1.5
      }
    },
    "nova-2-lite": {
      "name": "Nova 2 Lite",
      "model_id": "us.amazon.nova-2-lite-v1:0",
      "pricing_per_1M_tokens": {
        "input": 0.06,
        "output": 0.24
      }
    },
    "llama-3.2-11b": {
      "name": "Llama 3.2 11B",
      "model_id": "us.meta.llama3-2-11b-instruct-v1:0",
      "pricing_per_1M_tokens": {
        "input": 0.16,
        "output": 0.16
      }
    },
    "ministral-8b": {
      "name": "Ministral 8B",
      "model_id": "mistral.ministral-3-8b-instruct",
      "pricing_per_1M_tokens": {
        "input": 0.1,
        "output": 0.1
      }
    }
  },
  "tests": [
    {
      "test_name": "Complex Reasoning",
      "results": {
        "haiku-4.5": {
          "latency_s": 25.9,
          "input_tokens": 287,
          "output_tokens": 4096,
          "cost_usd": 0.020767,
          "response_chars": 10861
        },
        "qwen-3.2": {
          "latency_s": 26.02,
          "input_tokens": 213,
          "output_tokens": 2287,
          "cost_usd": 0.003537,
          "response_chars": 4589
        },
        "nova-2-lite": {
          "latency_s": 13.2,
          "input_tokens": 214,
          "output_tokens": 1817,
          "cost_usd": 0.000449,
          "response_chars": 4547
        },
        "llama-3.2-11b": {
          "latency_s": 25.27,
          "input_tokens": 175,
          "output_tokens": 4096,
          "cost_usd": 0.000683,
          "response_chars": 10364
        },
        "ministral-8b": {
          "latency_s": 18.26,
          "input_tokens": 171,
          "output_tokens": 4096,
          "cost_usd": 0.000427,
          "response_chars": 10721
        }
      },
      "rankings": {
        "fastest": "nova-2-lite",
        "cheapest": "ministral-8b"
      }
    },
    {
      "test_name": "Advanced Code Generation",
      "results": {
        "haiku-4.5": {
          "latency_s": 18.01,
          "input_tokens": 232,
          "output_tokens": 4096,
          "cost_usd": 0.020712,
          "response_chars": 10969
        },
        "qwen-3.2": {
          "latency_s": 23.47,
          "input_tokens": 161,
          "output_tokens": 2043,
          "cost_usd": 0.003145,
          "response_chars": 6183
        },
        "nova-2-lite": {
          "latency_s": 13.9,
          "input_tokens": 177,
          "output_tokens": 2284,
          "cost_usd": 0.000559,
          "response_chars": 7312
        },
        "llama-3.2-11b": {
          "latency_s": 25.32,
          "input_tokens": 139,
          "output_tokens": 4096,
          "cost_usd": 0.000678,
          "response_chars": 9313
        },
        "ministral-8b": {
          "latency_s": 6.94,
          "input_tokens": 142,
          "output_tokens": 1903,
          "cost_usd": 0.000205,
          "response_chars": 6604
        }
      },
      "rankings": {
        "fastest": "ministral-8b",
        "cheapest": "ministral-8b"
      }
    },
    {
      "test_name": "Multi-dimensional Analysis",
      "results": {
        "haiku-4.5": {
          "latency_s": 28.88,
          "input_tokens": 391,
          "output_tokens": 4096,
          "cost_usd": 0.020871,
          "response_chars": 5986
        },
        "qwen-3.2": {
          "latency_s": 33.42,
          "input_tokens": 290,
          "output_tokens": 2573,
          "cost_usd": 0.004005,
          "response_chars": 4053
        },
        "nova-2-lite": {
          "latency_s": 24.59,
          "input_tokens": 292,
          "output_tokens": 3791,
          "cost_usd": 0.000927,
          "response_chars": 8113
        },
        "llama-3.2-11b": {
          "latency_s": 24.81,
          "input_tokens": 253,
          "output_tokens": 4096,
          "cost_usd": 0.000696,
          "response_chars": 7358
        },
        "ministral-8b": {
          "latency_s": 14.01,
          "input_tokens": 244,
          "output_tokens": 3952,
          "cost_usd": 0.00042,
          "response_chars": 8726
        }
      },
      "rankings": {
        "fastest": "ministral-8b",
        "cheapest": "ministral-8b"
      }
    },
    {
      "test_name": "Technical Translation",
      "results": {
        "haiku-4.5": {
          "latency_s": 4.22,
          "input_tokens": 341,
          "output_tokens": 275,
          "cost_usd": 0.001716,
          "response_chars": 941
        },
        "qwen-3.2": {
          "latency_s": 0.95,
          "input_tokens": 233,
          "output_tokens": 104,
          "cost_usd": 0.000273,
          "response_chars": 587
        },
        "nova-2-lite": {
          "latency_s": 3.88,
          "input_tokens": 242,
          "output_tokens": 500,
          "cost_usd": 0.000135,
          "response_chars": 1632
        },
        "llama-3.2-11b": {
          "latency_s": 25.51,
          "input_tokens": 201,
          "output_tokens": 4096,
          "cost_usd": 0.000688,
          "response_chars": 8076
        },
        "ministral-8b": {
          "latency_s": 1.78,
          "input_tokens": 199,
          "output_tokens": 376,
          "cost_usd": 5.8e-05,
          "response_chars": 1807
        }
      },
      "rankings": {
        "fastest": "qwen-3.2",
        "cheapest": "ministral-8b"
      }
    },
    {
      "test_name": "Technical Translation EN-KO",
      "results": {
        "haiku-4.5": {
          "latency_s": 3.94,
          "input_tokens": 210,
          "output_tokens": 537,
          "cost_usd": 0.002895,
          "response_chars": 579
        },
        "qwen-3.2": {
          "latency_s": 3.68,
          "input_tokens": 187,
          "output_tokens": 362,
          "cost_usd": 0.000637,
          "response_chars": 585
        },
        "nova-2-lite": {
          "latency_s": 3.73,
          "input_tokens": 216,
          "output_tokens": 418,
          "cost_usd": 0.000113,
          "response_chars": 841
        },
        "llama-3.2-11b": {
          "latency_s": 23.99,
          "input_tokens": 175,
          "output_tokens": 4096,
          "cost_usd": 0.000683,
          "response_chars": 17135
        },
        "ministral-8b": {
          "latency_s": 3.25,
          "input_tokens": 183,
          "output_tokens": 813,
          "cost_usd": 0.0001,
          "response_chars": 1718
        }
      },
      "rankings": {
        "fastest": "ministral-8b",
        "cheapest": "ministral-8b"
      }
    }
  ],
  "summary": {
    "average_per_model": {
      "haiku-4.5": {
        "avg_latency_s": 16.19,
        "total_cost_usd": 0.066961,
        "avg_tokens": 2912
      },
      "qwen-3.2": {
        "avg_latency_s": 17.51,
        "total_cost_usd": 0.011596,
        "avg_tokens": 1691
      },
      "nova-2-lite": {
        "avg_latency_s": 11.86,
        "total_cost_usd": 0.002183,
        "avg_tokens": 1990
      },
      "llama-3.2-11b": {
        "avg_latency_s": 24.98,
        "total_cost_usd": 0.003428,
        "avg_tokens": 4285
      },
      "ministral-8b": {
        "avg_latency_s": 8.85,
        "total_cost_usd": 0.001208,
        "avg_tokens": 2416
      }
    },
    "rankings": {
      "by_latency": [
        {
          "rank": 1,
          "model": "Ministral 8B",
          "avg_latency_s": 8.85
        },
        {
          "rank": 2,
          "model": "Nova 2 Lite",
          "avg_latency_s": 11.86
        },
        {
          "rank": 3,
          "model": "Claude Haiku 4.5",
          "avg_latency_s": 16.19
        },
        {
          "rank": 4,
          "model": "Qwen 3 32B",
          "avg_latency_s": 17.51
        },
        {
          "rank": 5,
          "model": "Llama 3.2 11B",
          "avg_latency_s": 24.98
        }
      ],
      "by_cost": [
        {
          "rank": 1,
          "model": "Ministral 8B",
          "total_cost_usd": 0.001208
        },
        {
          "rank": 2,
          "model": "Nova 2 Lite",
          "total_cost_usd": 0.002183
        },
        {
          "rank": 3,
          "model": "Llama 3.2 11B",
          "total_cost_usd": 0.003428
        },
        {
          "rank": 4,
          "model": "Qwen 3 32B",
          "total_cost_usd": 0.011596
        },
        {
          "rank": 5,
          "model": "Claude Haiku 4.5",
          "total_cost_usd": 0.066961
        }
      ]
    }
  }
}