{
  "meta": {
    "title": "AWS Bedrock 경량 모델 비교 테스트",
    "date": "2026-02-15",
    "region": "us-east-1",
    "max_tokens": 4096,
    "total_tests": 5
  },
  "models": {
    "haiku-4.5": {
      "name": "Claude Haiku 4.5",
      "model_id": "us.anthropic.claude-haiku-4-5-20251001-v1:0",
      "pricing_per_1M_tokens": {
        "input": 1.0,
        "output": 5.0
      }
    },
    "qwen-3.2": {
      "name": "Qwen 3 32B",
      "model_id": "qwen.qwen3-32b-v1:0",
      "pricing_per_1M_tokens": {
        "input": 0.15,
        "output": 0.6
      }
    },
    "nova-2-lite": {
      "name": "Nova 2 Lite",
      "model_id": "us.amazon.nova-2-lite-v1:0",
      "pricing_per_1M_tokens": {
        "input": 0.3,
        "output": 2.5
      }
    },
    "llama-3.2-11b": {
      "name": "Llama 3.2 11B",
      "model_id": "us.meta.llama3-2-11b-instruct-v1:0",
      "pricing_per_1M_tokens": {
        "input": 0.16,
        "output": 0.16
      }
    },
    "ministral-8b": {
      "name": "Ministral 8B",
      "model_id": "mistral.ministral-3-8b-instruct",
      "pricing_per_1M_tokens": {
        "input": 0.15,
        "output": 0.15
      }
    }
  },
  "tests": [
    {
      "test_name": "Complex Reasoning",
      "results": {
        "haiku-4.5": {
          "latency_s": 24.78,
          "input_tokens": 287,
          "output_tokens": 4096,
          "cost_usd": 0.020767,
          "response_chars": 9366
        },
        "qwen-3.2": {
          "latency_s": 22.51,
          "input_tokens": 213,
          "output_tokens": 2090,
          "cost_usd": 0.001286,
          "response_chars": 4116
        },
        "nova-2-lite": {
          "latency_s": 12.61,
          "input_tokens": 214,
          "output_tokens": 1986,
          "cost_usd": 0.005029,
          "response_chars": 4157
        },
        "llama-3.2-11b": {
          "latency_s": 23.79,
          "input_tokens": 175,
          "output_tokens": 4096,
          "cost_usd": 0.000683,
          "response_chars": 11087
        },
        "ministral-8b": {
          "latency_s": 16.34,
          "input_tokens": 171,
          "output_tokens": 3671,
          "cost_usd": 0.000576,
          "response_chars": 10191
        }
      },
      "rankings": {
        "fastest": "nova-2-lite",
        "cheapest": "ministral-8b"
      }
    },
    {
      "test_name": "Advanced Code Generation",
      "results": {
        "haiku-4.5": {
          "latency_s": 17.72,
          "input_tokens": 232,
          "output_tokens": 3831,
          "cost_usd": 0.019387,
          "response_chars": 9644
        },
        "qwen-3.2": {
          "latency_s": 14.82,
          "input_tokens": 161,
          "output_tokens": 2046,
          "cost_usd": 0.001252,
          "response_chars": 6525
        },
        "nova-2-lite": {
          "latency_s": 10.34,
          "input_tokens": 177,
          "output_tokens": 1894,
          "cost_usd": 0.004788,
          "response_chars": 6463
        },
        "llama-3.2-11b": {
          "latency_s": 24.53,
          "input_tokens": 139,
          "output_tokens": 4096,
          "cost_usd": 0.000678,
          "response_chars": 14002
        },
        "ministral-8b": {
          "latency_s": 6.1,
          "input_tokens": 142,
          "output_tokens": 1655,
          "cost_usd": 0.00027,
          "response_chars": 6263
        }
      },
      "rankings": {
        "fastest": "ministral-8b",
        "cheapest": "ministral-8b"
      }
    },
    {
      "test_name": "Multi-dimensional Analysis",
      "results": {
        "haiku-4.5": {
          "latency_s": 30.59,
          "input_tokens": 391,
          "output_tokens": 4096,
          "cost_usd": 0.020871,
          "response_chars": 5450
        },
        "qwen-3.2": {
          "latency_s": 26.76,
          "input_tokens": 290,
          "output_tokens": 2406,
          "cost_usd": 0.001487,
          "response_chars": 3981
        },
        "nova-2-lite": {
          "latency_s": 18.03,
          "input_tokens": 292,
          "output_tokens": 2720,
          "cost_usd": 0.006888,
          "response_chars": 4966
        },
        "llama-3.2-11b": {
          "latency_s": 24.01,
          "input_tokens": 253,
          "output_tokens": 4096,
          "cost_usd": 0.000696,
          "response_chars": 7333
        },
        "ministral-8b": {
          "latency_s": 18.31,
          "input_tokens": 244,
          "output_tokens": 4096,
          "cost_usd": 0.000651,
          "response_chars": 7844
        }
      },
      "rankings": {
        "fastest": "nova-2-lite",
        "cheapest": "ministral-8b"
      }
    },
    {
      "test_name": "Technical Translation",
      "results": {
        "haiku-4.5": {
          "latency_s": 2.55,
          "input_tokens": 341,
          "output_tokens": 281,
          "cost_usd": 0.001746,
          "response_chars": 1025
        },
        "qwen-3.2": {
          "latency_s": 0.95,
          "input_tokens": 233,
          "output_tokens": 108,
          "cost_usd": 0.0001,
          "response_chars": 596
        },
        "nova-2-lite": {
          "latency_s": 4.25,
          "input_tokens": 242,
          "output_tokens": 719,
          "cost_usd": 0.00187,
          "response_chars": 3476
        },
        "llama-3.2-11b": {
          "latency_s": 23.62,
          "input_tokens": 201,
          "output_tokens": 4096,
          "cost_usd": 0.000688,
          "response_chars": 8637
        },
        "ministral-8b": {
          "latency_s": 1.88,
          "input_tokens": 199,
          "output_tokens": 311,
          "cost_usd": 7.7e-05,
          "response_chars": 1368
        }
      },
      "rankings": {
        "fastest": "qwen-3.2",
        "cheapest": "ministral-8b"
      }
    },
    {
      "test_name": "Technical Translation EN-KO",
      "results": {
        "haiku-4.5": {
          "latency_s": 3.69,
          "input_tokens": 210,
          "output_tokens": 534,
          "cost_usd": 0.00288,
          "response_chars": 566
        },
        "qwen-3.2": {
          "latency_s": 3.65,
          "input_tokens": 187,
          "output_tokens": 374,
          "cost_usd": 0.000252,
          "response_chars": 621
        },
        "nova-2-lite": {
          "latency_s": 3.14,
          "input_tokens": 216,
          "output_tokens": 412,
          "cost_usd": 0.001095,
          "response_chars": 863
        },
        "llama-3.2-11b": {
          "latency_s": 23.65,
          "input_tokens": 175,
          "output_tokens": 4096,
          "cost_usd": 0.000683,
          "response_chars": 16857
        },
        "ministral-8b": {
          "latency_s": 4.2,
          "input_tokens": 183,
          "output_tokens": 836,
          "cost_usd": 0.000153,
          "response_chars": 1793
        }
      },
      "rankings": {
        "fastest": "nova-2-lite",
        "cheapest": "ministral-8b"
      }
    }
  ],
  "summary": {
    "average_per_model": {
      "haiku-4.5": {
        "avg_latency_s": 15.87,
        "total_cost_usd": 0.065651,
        "avg_tokens": 2860
      },
      "qwen-3.2": {
        "avg_latency_s": 13.74,
        "total_cost_usd": 0.004377,
        "avg_tokens": 1622
      },
      "nova-2-lite": {
        "avg_latency_s": 9.67,
        "total_cost_usd": 0.01967,
        "avg_tokens": 1774
      },
      "llama-3.2-11b": {
        "avg_latency_s": 23.92,
        "total_cost_usd": 0.003428,
        "avg_tokens": 4285
      },
      "ministral-8b": {
        "avg_latency_s": 9.37,
        "total_cost_usd": 0.001726,
        "avg_tokens": 2302
      }
    },
    "rankings": {
      "by_latency": [
        {
          "rank": 1,
          "model": "Ministral 8B",
          "avg_latency_s": 9.37
        },
        {
          "rank": 2,
          "model": "Nova 2 Lite",
          "avg_latency_s": 9.67
        },
        {
          "rank": 3,
          "model": "Qwen 3 32B",
          "avg_latency_s": 13.74
        },
        {
          "rank": 4,
          "model": "Claude Haiku 4.5",
          "avg_latency_s": 15.87
        },
        {
          "rank": 5,
          "model": "Llama 3.2 11B",
          "avg_latency_s": 23.92
        }
      ],
      "by_cost": [
        {
          "rank": 1,
          "model": "Ministral 8B",
          "total_cost_usd": 0.001726
        },
        {
          "rank": 2,
          "model": "Llama 3.2 11B",
          "total_cost_usd": 0.003428
        },
        {
          "rank": 3,
          "model": "Qwen 3 32B",
          "total_cost_usd": 0.004377
        },
        {
          "rank": 4,
          "model": "Nova 2 Lite",
          "total_cost_usd": 0.01967
        },
        {
          "rank": 5,
          "model": "Claude Haiku 4.5",
          "total_cost_usd": 0.065651
        }
      ]
    }
  }
}